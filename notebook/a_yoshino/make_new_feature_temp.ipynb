{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = '../input/train.csv'\n",
    "TEST_DATA_PATH = '../input/test.csv'\n",
    "\n",
    "origin_train = pd.read_csv(TRAIN_DATA_PATH)\n",
    "origin_test = pd.read_csv(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 1)\n"
     ]
    }
   ],
   "source": [
    "features = origin_train.columns[2:]\n",
    "target = pd.DataFrame(origin_train, columns=['target'])\n",
    "print(target.shape)\n",
    "df_train = pd.DataFrame(origin_train, columns=features)\n",
    "df_test = pd.DataFrame(origin_test, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "trainとtestの新しい特徴量を作る関数\n",
    "feature_num = var_{feature_num}の特徴量を作る\n",
    "\"\"\"\n",
    "def new_feature(df_train, df_test, feature_num):   \n",
    "    new_train = pd.DataFrame([])\n",
    "    new_test = pd.DataFrame([])\n",
    "    for i in range(feature_num+1, 200):\n",
    "        new_train[f'var_{feature_num}_{i}'] = df_train[f'var_{feature_num}'] + df_train[f'var_{i}']\n",
    "        new_test[f'var_{feature_num}_{i}'] = df_test[f'var_{feature_num}'] + df_test[f'var_{i}']\n",
    "    return new_train, new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "元のデータとスタックして学習させたいときはこの関数使う\n",
    "スタックしないで学習するときはnew_featureの戻り値をtrain, testで受け取って学習させる\n",
    "\"\"\"\n",
    "\n",
    "def stack_data(feature_num):\n",
    "    new_train, new_test = new_feature(df_train, df_test, feature_num)\n",
    "    train = new_train\n",
    "    test =  new_test\n",
    "    return train, test, new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ストレージに余裕があればfeature_numをfor文で回して特徴量ごとのcsvファイル作ってあとでまとめて学習も有り\n",
    "そのまま学習したければ下記の関数はコメントアウトして大丈夫\n",
    "\"\"\"\n",
    "def new_feature_csv(feature_num, new_train, new_test):\n",
    "    new_train.to_csv(f'../output/train_new_var_{feature_num}.csv')\n",
    "    new_test.to_csv(f'../output/test_new_var_{feature_num}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ログの出力\n",
    "logger = logging.getLogger()\n",
    "now = datetime.datetime.now()\n",
    "handler = logging.FileHandler(\"../log/make_new_feature_log{0:%Y%m%d%H%M%S}.csv\".format(now), encoding=\"UTF-8\")\n",
    "handler.setLevel(logging.INFO)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-9b8a676fc62d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#新しい特徴量ファイルの作成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mnew_feature_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-9bca92e528c7>\u001b[0m in \u001b[0;36mnew_feature_csv\u001b[0;34m(feature_num, new_train, new_test)\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnew_feature_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnew_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../output/train_new_var_{feature_num}.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mnew_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../output/test_new_var_{feature_num}.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 3020\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3022\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnicodeWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    300\u001b[0m                                   \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                                   \u001b[0mdate_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                                   quoting=self.quoting)\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mto_native_types\u001b[0;34m(self, slicer, na_rep, float_format, decimal, quoting, **kwargs)\u001b[0m\n\u001b[1;32m   1995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for num in range(3, 200):\n",
    "    feature_num = num\n",
    "    \n",
    "    logger.info(f\"START: var_{feature_num}\")\n",
    "    \n",
    "    train, test, new_train = stack_data(feature_num)\n",
    "    #新しい特徴量ファイルの作成\n",
    "    new_feature_csv(feature_num, train, test)\n",
    "    \n",
    "    features = new_train.columns\n",
    "\n",
    "    param = {\n",
    "        'bagging_freq': 5,\n",
    "        'bagging_fraction': 0.4,\n",
    "        'boost_from_average':'false',\n",
    "        'boost': 'gbdt',\n",
    "        'feature_fraction': 0.05,\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': -1,  \n",
    "        'metric':'auc',\n",
    "        'min_data_in_leaf': 80,\n",
    "        'min_sum_hessian_in_leaf': 10.0,\n",
    "        'num_leaves': 13,\n",
    "        'num_threads': 8,\n",
    "        'tree_learner': 'serial',\n",
    "        'objective': 'binary', \n",
    "        'verbosity': 1\n",
    "    }\n",
    "\n",
    "    folds = StratifiedKFold(n_splits=10, shuffle=False, random_state=44000)\n",
    "    oof = np.zeros(len(train))\n",
    "    predictions = np.zeros(len(test))\n",
    "    feature_importance = pd.DataFrame()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "        print(\"Fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "\n",
    "        num_round = 30000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 3000)\n",
    "        oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "        fold_importance = pd.DataFrame()\n",
    "        fold_importance[\"Feature\"] = features\n",
    "        fold_importance[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance[\"fold\"] = fold_ + 1\n",
    "        feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "        predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "    print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\n",
    "    logger.info(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\n",
    "\n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "    #取得したimportanceの結果csv\n",
    "    feature_importance.to_csv(f\"../output/new_feature_importance_var{feature_num}.csv\", index=False)\n",
    "\n",
    "    score = round(roc_auc_score(target, oof), 4)\n",
    "    sub = pd.DataFrame({\"ID_code\": origin_test.ID_code.values})\n",
    "    sub[\"target\"]=predictions\n",
    "    sub.to_csv(f\"submission_new_var{feature_num}_{score}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
