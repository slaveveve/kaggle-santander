{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a_yoshino/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n",
      "/Users/a_yoshino/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV\n",
    "import datetime\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = '../input/train.csv'\n",
    "TEST_DATA_PATH = '../input/test.csv'\n",
    "\n",
    "origin_train = pd.read_csv(TRAIN_DATA_PATH)\n",
    "origin_test = pd.read_csv(TEST_DATA_PATH)\n",
    "target = origin_train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_feature():\n",
    "    \"\"\"\n",
    "    targetとの相関が高い新しい特徴量を作成する\n",
    "    \"\"\"\n",
    "    \n",
    "    #相関0.０７以上\n",
    "    border= 0.07\n",
    "    \n",
    "    best_corr_var = pd.read_csv(f\"../output/best_corr_var.csv\").rename(columns={\"Unnamed: 0\":\"ID_code\", \"0\":\"corr\"})\n",
    "    #相関で並び替え→上位を取得\n",
    "    var_name_li = best_corr_var.sort_values(\"corr\", ascending=False)[best_corr_var[\"corr\"]>border][\"ID_code\"]\n",
    "    id_code_li = []\n",
    "    for var_name in var_name_li.values:\n",
    "        id_code_li.append(var_name.replace(\"var_\", \"\").split(\"_\"))\n",
    "    \n",
    "    #新しい特徴量の作成\n",
    "    new_train = pd.DataFrame([])\n",
    "    new_test = pd.DataFrame([])\n",
    "    for id_code_pair in id_code_li:\n",
    "        var1 = f\"var_{id_code_pair[0]}\"\n",
    "        var2 = f\"var_{id_code_pair[1]}\"\n",
    "        new_train_feature = origin_train[var1] + origin_train[var2]\n",
    "        new_test_feature = origin_test[var1] + origin_test[var2]\n",
    "        \n",
    "        new_train = pd.concat([new_train, new_train_feature], axis=1)\n",
    "        new_test = pd.concat([new_test, new_test_feature], axis=1)\n",
    "    \n",
    "    return new_train, new_test, var_name_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a_yoshino/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "new_train, new_test, var_name_li = get_new_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.columns = var_name_li.values\n",
    "new_test.columns = var_name_li.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = origin_train[\"target\"]\n",
    "train = pd.concat([origin_train, new_train], axis=1).drop(\"ID_code\", axis=1).drop(\"target\", axis=1)\n",
    "test = pd.concat([origin_test, new_test], axis=1).drop(\"ID_code\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(x,y,t=2):\n",
    "    xs,xn = [],[]\n",
    "    for i in range(t):\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn])\n",
    "    y = np.concatenate([y,ys,yn])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.4,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.05,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,  \n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.900532\tvalid_1's auc: 0.891371\n",
      "[2000]\ttraining's auc: 0.922232\tvalid_1's auc: 0.911308\n",
      "[3000]\ttraining's auc: 0.932501\tvalid_1's auc: 0.920469\n",
      "[4000]\ttraining's auc: 0.938705\tvalid_1's auc: 0.925576\n",
      "[5000]\ttraining's auc: 0.94299\tvalid_1's auc: 0.929202\n",
      "[6000]\ttraining's auc: 0.946567\tvalid_1's auc: 0.931944\n",
      "[7000]\ttraining's auc: 0.949742\tvalid_1's auc: 0.934223\n",
      "[8000]\ttraining's auc: 0.952622\tvalid_1's auc: 0.936341\n",
      "[9000]\ttraining's auc: 0.955274\tvalid_1's auc: 0.938086\n",
      "[10000]\ttraining's auc: 0.957754\tvalid_1's auc: 0.939778\n",
      "[11000]\ttraining's auc: 0.959881\tvalid_1's auc: 0.940973\n",
      "[12000]\ttraining's auc: 0.96197\tvalid_1's auc: 0.942136\n",
      "[13000]\ttraining's auc: 0.963743\tvalid_1's auc: 0.943049\n",
      "[14000]\ttraining's auc: 0.965583\tvalid_1's auc: 0.944008\n",
      "[15000]\ttraining's auc: 0.96718\tvalid_1's auc: 0.944717\n",
      "[16000]\ttraining's auc: 0.968705\tvalid_1's auc: 0.945351\n",
      "[17000]\ttraining's auc: 0.970114\tvalid_1's auc: 0.945916\n",
      "[18000]\ttraining's auc: 0.971526\tvalid_1's auc: 0.946422\n",
      "[19000]\ttraining's auc: 0.972835\tvalid_1's auc: 0.946896\n",
      "[20000]\ttraining's auc: 0.974062\tvalid_1's auc: 0.947343\n",
      "[21000]\ttraining's auc: 0.975263\tvalid_1's auc: 0.947755\n",
      "[22000]\ttraining's auc: 0.976412\tvalid_1's auc: 0.948071\n",
      "[23000]\ttraining's auc: 0.97754\tvalid_1's auc: 0.948422\n",
      "[24000]\ttraining's auc: 0.978584\tvalid_1's auc: 0.948783\n",
      "[25000]\ttraining's auc: 0.979554\tvalid_1's auc: 0.949069\n",
      "[26000]\ttraining's auc: 0.98053\tvalid_1's auc: 0.949363\n",
      "[27000]\ttraining's auc: 0.981491\tvalid_1's auc: 0.949641\n",
      "[28000]\ttraining's auc: 0.982327\tvalid_1's auc: 0.949834\n",
      "[29000]\ttraining's auc: 0.983193\tvalid_1's auc: 0.950014\n",
      "[30000]\ttraining's auc: 0.983975\tvalid_1's auc: 0.950169\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[30000]\ttraining's auc: 0.983975\tvalid_1's auc: 0.950169\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=10, shuffle=False, random_state=44000)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "feature_importance = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    #argument\n",
    "    trn_train, trn_target= augment(np.array(train.iloc[trn_idx]), np.array(target.iloc[trn_idx]))\n",
    "    trn_data = lgb.Dataset(trn_train, label=trn_target)\n",
    "    val_train, val_target= augment(np.array(train.iloc[val_idx]), np.array(target.iloc[val_idx]))\n",
    "    val_data = lgb.Dataset(val_train, label=val_target)\n",
    "\n",
    "    num_round = 30000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 3000)\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance = pd.DataFrame()\n",
    "    fold_importance[\"Feature\"] = features\n",
    "    fold_importance[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance[\"fold\"] = fold_ + 1\n",
    "    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (feature_importance[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:6000].index)\n",
    "best_features = feature_importance.loc[feature_importance.Feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,30))\n",
    "sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n",
    "plt.title('Features importance (averaged/folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('FI.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.to_csv(f\"importamce_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = round(roc_auc_score(target, oof), 4)\n",
    "sub = pd.DataFrame({\"ID_code\": test.index})\n",
    "sub[\"target\"]=predictions\n",
    "sub.to_csv(f\"submission_new_var{file_name}_{score}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
