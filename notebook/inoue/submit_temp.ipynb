{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitする用のテンプレート\n",
    "\n",
    "特徴量を読み込んで `LightGBM` を使用したモデルを使用して判別を行います。\n",
    "\n",
    "## 使用方法\n",
    "\n",
    "1. 特徴となるデータ(csv)をあらかじめ用意しておく。  \n",
    "2. 用意したデータのパスを[2]の `train_data_list` と `test_data_list` に追加する。\n",
    "3. このノートを実行する。\n",
    "\n",
    "## 読み込むデータの形式について\n",
    "\n",
    "以下のように `ID_code` を主キーとしたCSVデータを用意してください。\n",
    "\n",
    "| ID_code | feature1 | feature2 |\n",
    "|:-----------|------------:|:------------:|\n",
    "| value | value | value |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from IPython.core.display import display\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = [\n",
    "#     \"exam→\" '../input/sample_train.csv'\n",
    "    'train.csv'\n",
    "]\n",
    "test_data_list = [\n",
    "#     \"exam→\" '../input/sample_test.csv'\n",
    "    'test.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 202)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(200000, 201)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(pd.read_csv( '../input/sample_train').shape)\n",
    "display(pd.read_csv( 'train.csv').shape)\n",
    "\n",
    "\n",
    "# display(pd.read_csv( '../input/sample_test').shape)\n",
    "display(pd.read_csv( 'test.csv').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "for path in train_data_list: \n",
    "    if len(train) == 0:\n",
    "        train = pd.read_csv(path)\n",
    "    else:\n",
    "        other = pd.read_csv(path) \n",
    "        train = pd.merge(train, other, on='ID_code', how='left')  \n",
    "\n",
    "test = pd.DataFrame()\n",
    "for path in test_data_list: \n",
    "    if len(test) == 0: \n",
    "        test= pd.read_csv(path)\n",
    "    else: \n",
    "        other = pd.read_csv(path) \n",
    "        test = pd.merge(test, other, on='ID_code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if c not in ['ID_code', 'target']]\n",
    "target = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.4,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.05,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,  \n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=9, shuffle=True, random_state=2019)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "feature_importance = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "\n",
    "    num_round = 8000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 250)\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance = pd.DataFrame()\n",
    "    fold_importance[\"Feature\"] = features\n",
    "    fold_importance[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance[\"fold\"] = fold_ + 1\n",
    "    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (feature_importance[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:150].index)\n",
    "best_features = feature_importance.loc[feature_importance.Feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,28))\n",
    "sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n",
    "plt.title('Features importance (averaged/folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('FI.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.datetime.now().strftime('%Y%m%d%H%M')\n",
    "sub_df = pd.DataFrame({\"ID_code\":test[\"ID_code\"].values})\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(f\"submission-{date}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
